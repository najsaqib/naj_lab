title,abstract
Accelerate AI/ML Deployments with Enterprise-Grade MLOps,
Feathr: Scalable Feature Store that opens the Window to Infinite Possibilities,"In this session, we will dive deep into Feathr, taking you on a journey into this scalable open-source feature store which has now joined the Linux Foundation AI and Data ecosystem. Feathr has been battle-tested in LinkedIn powering high scale ML applications, supporting 100s of training and inferencing pipelines. This enables feature sharing among teams, leading to significant business metrics gain.

We will dive into some of the key highlights – rich UDF support, dynamic type casting, point-in-time joins, time aware sliding window aggregation, support for derived features, support for advanced ML scenarios and much more!

Feathr has a cloud-friendly scalable architecture and has been made available as an easy deployment on Azure. We will go over the key components – a central registry to store and share feature definitions, offline and online data store connectors, tight integration with Spark to run transformations and integration with various services using the Python SDK.

We will also showcase how Feathr can be used to build an end-to-end solution and go over some of the key customer patterns based on real life customer usage"
How to Model Public Opinions in the Media Age,"The truths and lies of survey data, or how to model public opinions in the media age.

“ESG is a scam. It has been weaponized by phony social justice warriors.” Elon Musk ESG tweet.May 21, 2022
Do you think Elon Musk is right? What do other people think of ESG?

In the big data era, surprisingly, surveys still play a crucial role in market research. We know that people often have self-servicing biases in surveys. So how do you overcome these self-servicing biases in market research data?

I will talk about practical methods to model survey data effectively to avoid cheaters and self-attestation tendencies to lie, using statistics, analytics, and ML/AI.

In my talk, I will explain how to treat surveys as big data and combine them with additional data sources for effective modeling. Using benchmarking techniques and novel modeling approaches, we may find the underlying gems in this somewhat old-fashioned yet still relevant information source.

We will delve into how to understand what people think, feel, and what drives consumer activities by using a combination of surveys, mainstream and social media, reviews, and other data sources, by applying statistical methods combined with NLP and deep learning. I will demonstrate these techniques with a few thought-provoking examples from the vastly emerging data on Environmental, Social, and Governance (ESG) perceptions."
Creating An Ethical AI Environment,"We are at a pivotal time in our AI development and adoption where we still have the ability to create a world where AI is a force for good, instead of world where AI is used deepen inequalities and divides. To do this, we much create an ethical AI environment to move forward. Key takeaways from this talk include:
* The current state of ethical AI
* How develop an ethical AI environment
* The future of coexisting with machines"
AI in a Minefield: Learning from Poisoned Data,"Data poisoning is one of the main threats on AI systems. When malicious actors have even limited control over the data used for training a model, they can try to fail the training process, prevent it from convergence, skewing the model or install so-called ML backdoors – areas where this model makes incorrect decisions, usually areas of interest for the attacker. This threat is especially applicable when security technologies use anomaly detection mechanisms on top of a normality model constructed from previously seen traffic data. When the traffic originates from unreliable sources, which may be partially controlled by malicious actors, the learning process needs to be designed under the assumption that data poisoning attempts are very likely to occur.

In this talk, we will present the challenges of learning from dirty data, overview data poisoning attacks on different systems like Spam detection, image classification and rating systems, discuss the problem of learning from web traffic - probably the dirtiest data in the world, and explain different approaches for learning from dirty data and poisoned data. We will focus on threshold-learning mitigation for data poisoning, aiming to reduce the impact of any single data source, and discuss a mundane but crucial aspect of threshold learning – memory complexity. We will present a robust learning scheme optimized to work efficiently on streamed data with bounded memory consumption. We will give examples from the web security arena with robust learning of URLs, parameters, character sets, cookies and more."
An Intuition-Based Approach to Reinforcement Learning,"Reinforcement learning (RL) has achieved remarkable success in various tasks, such as defeating all-human teams in MMP (massive multi-player) games, advances in robotics, and astonishing results in the protein folding problem in chemistry. Expertise in RL requires strong knowledge of machine learning, statistics, and areas of mathematics. Moreover, RL contains many concepts that seem ""fuzzy"" and hence can be challenging for beginners who are trying to learn RL. However, this session provides the intuition of various RL concepts, such as exploit/explore and maximization of expected reward, along with real-life examples of these concepts. Attendees will also see a comparison of greedy versus epsilon greedy, and why epsilon greedy can solve tasks that cannot be solved using a greedy approach. Some of the preceding concepts will be illustrated during the presentation of the n-chain task in RL, whose solution clearly requires an epsilon greedy algorithm. The target audience for this session is for beginners who have no experience with RL."
Denoising Diffusion-based Generative Modeling,"Diffusion-based generative models such as DALL·E 2 have achieved exceptional image generation quality. Unlike other generative models based on explicit representations of probability distributions (e.g., autoregressive) or implicit sampling procedures (e.g., GANs), diffusion models learn directly the vector field of gradients of the data distribution (scores). This framework allows flexible architectures, requires no sampling during training or the use of adversarial training methods. These score-based generative models enable exact likelihood evaluation, achieve state-of-the-art sample quality, and can be used to improve performance in a variety of inverse problems, including medical imaging."
Building & Selling AI Startups,Taylor will share some of the biggest regrets and lessons he has learned after a decade of building and selling AI startups. From Sequoia's HireVue to his own deep-learning startup Zeff which was acquired by DataRobot. Taylor will discuss key competencies and lessons needed when it comes to selling AI software in the market.
"Introduction to Generative Art with Stable Diffusion, presented by HP Inc","Hot on the heels of popular text-to-image Generative Art models like OpenAI's DALLE 2 and Midjourney, Stable Diffusion is an open source Latent Diffusion model that can be used to create images from just a few words. This talk will go through high level details of how the model was built and trained, and some of the precursors models that it built upon. Then it will move to some comments on the ethical implications of AI art models generally and ethical considerations for those using stable diffusion and models like it. The main portion of the talk will be covering with how to get started using Stable Diffusion. This will help those even with limited background in ML or deep learning techniques to get an understanding of practically how to work with the model. This section will also focus on tips, tricks and examples to improve your output images as well as hardware considerations when running this powerful model locally. Finally we will finish with a couple of examples of how this model can be used in a few specific workflows or applications and some examples of what future generative art models may be able to do."
"Toward Robust, Knowledge-Rich Natural Language Processing","Enormous amounts of ever-changing knowledge are available online in diverse textual styles and diverse formats. Recent advances in deep learning algorithms and large-scale datasets are spurring progress in many Natural Language Processing (NLP) tasks, including question answering. Nevertheless, these models cannot scale up when task-annotated training data are scarce. This talk presents my lab's work toward building general-purpose models in NLP and how to systematically evaluate them. I present a new meta-dataset – called super-Natural Instructions – that includes a variety of NLP tasks and their descriptions to evaluate cross-task generalization. Then, I introduce a new meta training approach that can solve more than 1600 NLP tasks only from their descriptions and a few examples."
A New Era of Applied AI: How to Accelerate Enterprise Adoption of AI for Business Impact,"Global spend on AI continues to explode, even during the current economic climate, as C-Suite and senior executives realize the importance AI has and will have on their business models. Despite these massive investments, enterprises are challenged to show ROI from their AI initiatives due to complexity and lack of business adoption.

Gaurav will share his perspective on market trends in machine learning and AI as well as the challenges current enterprises face to deliver business value from data-centric AI. While business users and developers work in separate environments with separate tools, he will cover how to effectively bridge AI with business decision makers, the capabilities required, and example of doing this with a universal semantic layer."
Operationalizing Organizational Knowledge with Data-Centric AI,"Data-centric AI broadly describes the idea that *data*, rather than models, is increasingly the crux of success or failure in AI for many settings and use cases. More specifically, data-centric AI defines ML development workflows that center around principally iterating on the *training data*–e.g. labeling, sampling, slicing, augmenting, etc.–rather than the model architecture. In this talk, I'll describe how programmatic or weak supervision can not only facilitate these data-centric workflows (in ways that manual labeling cannot), but more importantly, will present an overview about how it can serve as an API for rich organizational knowledge sources, presenting recent technical results and user case studies."
Real-time Data Science Made Easy,"By 2025, analysts estimate that 30% of generated data will be real-time data.  This is 52ZB of real-time data per year and is roughly the amount of total data produced in 2020!  Soon, almost every data scientist and data engineer will be working with real-time data.  The future of data science is real-time. Existing technologies for working with static data fail when applied to real-time data because they have no way to incrementally update calculations and visualizations.  To make such enormous volumes of changing data useful, we need a toolkit for managing data, performing data science, and visualizing results in real-time.  In this talk, we will explore production-quality, real-time data science using the current leading open, real-time technologies:  Kafka, redpanda, ksqlDB, Materialize, and Deephaven Community Core.

Session Outline:
Concepts that will be discussed:
 Key components needed in a real-time data analytics system and how to choose the best open
options for your use case.
 Why are current static technologies, such as SQL and Pandas, unsuited to real-time data science?
(Transactional DB vs streaming table)
 Design patterns for building flexible real-time workflows.
 Efficiently publishing real-time data to many users in a programming language agnostic way.
 Using both real-time and static data in the same query. 
 Data exploration, visualization, and dashboards in real-time.
 Query language selection for data science: SQL (ksqlDB and Materialize) vs data-frame
(Deephaven).
 Working with time series.
 Real-time AI/ML on streams of data.
 Do current tools, such as Pandas, Matplotlib, and TensorFlow, have a place in a real-time world?"
Turning your Data/AI Algorithms into Full Web Apps in no Time with Taipy,"In the Python open-source eco-system, many packages are available that cater to:
- the building of great algorithms
- the visualization of data
- back-end functions
Despite this, over 85% of Data Science Pilots remain pilots and do not make it to the production stage.
With Taipy, Data Scientists/Python Developers will be able to build great pilots as well as stunning production-ready applications for end-users.
Taipy provides two independent modules: Taipy GUI and Taipy Core.

In this talk, we will demonstrate how:
Taipy-GUI goes way beyond the capabilities of the standard graphical stack: Gradio, Streamlit, Dash, etc.
Taipy Core is simpler yet more powerful than the standard Python back-end stack: Airflow, MLFlow, Luigi, etc.

Bio: "
Inclusive Search and Recommendations,"To truly bring everyone the inspiration to create a life they love, Pinterest is committed to content diversity and to developing inclusive search and recommendation engines. A top request we hear from Pinners is that they want to feel represented in the product. This is why we built the skin tone range and hair pattern technologies. These machine learning technologies are paving the way for more inclusive inspirations in Search and our augmented reality technology Try-On, and driving advances for more diverse recommendations across the platform. Developing inclusive AI in production requires an iterative and collaborative approach. We have learned the importance of building inclusive systems by design, of measuring to make progress, and of leveraging both artificial and human intelligence. We recognize that these challenges are multi-disciplinary, not just technical. In this talk, we describe sources of bias in ML for search and recommendation systems, techniques to mitigate bias, and production examples from our work at Pinterest to build inclusive search and recommendations."
Emerging Approaches to AI Governance: Tech-Led vs Policy-Led,"Over the past few years, many have become more familiar with the potential risks posed to the improper deployment and usage of AI/ML systems. Companies of almost all sizes and across almost all sectors have seen examples of major AI failures, leading into significant decay in trust of these systems. As a result, stakeholders across organizations have emerged as interested in remediating these risks and getting a handle on AI -- in owning AI governance. Some are drawn to technical capabilities which promise solutions to ethical problems and enable quality. Others rely on existing compliance and policy methods to enforce standards. In this session, we will describe what these different approaches look like, the pros and cons of each, and considerations to build a robust framework around AI governance that engages technical, business, and compliance teams."
5 Questions Business Leaders Should Ask When Investing in Machine Learning Projects,"While there is a lot of pressure on business leaders to leverage machine learning in their areas, there isn't a clear framework of how these leaders should decide on which ML projects to invest in and which ones not to invest in! This is a key reason why many ML project get left mid-way and many others don't show ROI post implementation - even after thousands of human hours have been put into them. In this session, you, as a business leader, will learn 5 questions that you must answer in deciding which ML project to invest - from prioritization to measuring real impact. I'll also share my experience seeing ML projects in action, driving real value, with use cases covering various industries."
“DataOps 2.0” – How the Changing MLOps Landscape is Reinventing DataOps,"Today, commercial deployments of MLOps at a scale are going through an evolutionary change across almost all verticals and use cases. Notably, deployment and product at a scale are seeing a whole slew of commercialization issues arise as “edge cases” become more significant at scales of thousands, millions or even billions. As a result, “traditional pre-deployment training” is no longer sufficient to ensure quality and reliability standards in production, especially in edge devices. Personalization at the edge - cards, phones, cameras, etc. need to be continuously trained with custom & specific data relevant to their individual usage or environment to be safe and accurate. For example, the neural networks that govern the way an autonomous vehicle drives in New York City is not the same in Kansas City or Mexico City, and surely not in Yellowstone National Park. The explosions of data streams from billions of “sensors” in real & virtual worlds need to be constantly processed for retraining models and data preparation is getting extremely complex as use-cases strive to replicate normal human behavior.

The selection of a DataOps partner to navigate this scale, fragmentation, volume and complexity is undergoing major metamorphosis, too. Selection criteria based on basic workforce efficiency and cost metrics is not sufficient. In fact, they could be counter-productive to your goals of robust, production-ready ML applications. Key KPIs that are fast emerging as critical for almost all ML applications such as data preparation and annotation (DataOps) is no longer a “one way street” process feeding the MLOps cycle, but is intricately fused to it at multiple stages. The talent ask is now beyond someone who can draw polygons around objects in an image and they also need to be subject matter experts with significant experience in a vertical or use-case. The usage of a “crowd” is no longer the optimal solution for many applications. The technical ability (technique) needed for these complex DataOps projects can only be groomed through long-time employment, experience, and comprehensive training. Technology’s role in DataOps has become more important than ever before. A robust workforce, project, task, and data management platform is one of the most critical pieces to cater to the scale. Usage of tooling to improve productivity, efficiency, accuracy as well as automation are also must-haves in an efficient, scalable DataOps platform. For example, Edge case analysis is now a critical part of scaling in production. An edge case in a pilot deployment will surely be unacceptably common in a commercial fleet. This requires tools and talent to work synergistically, with a deep understanding of the client’s application and training methodology. iMerit ensures continued success for your MLOps application, development, evaluation and tracking metrics across all 3 criteria above is very critical. Only a few DataOps companies have managed to make the transition and provide a robust integrated end-to-end solution. A still smaller fraction can keep pace with the scale, performance and automation roadmaps of this fast-changing industry, and iMerit is at the helm as one of the industry leaders."
"Look, Listen, Read: Unified AI with TorchMultimodal","Multimodal AI is a fast-growing field where deep neural networks are trained using multiple types of input data simultaneously (e.g. text, image, video, audio). Multimodal models perform better in content understanding applications, and are setting new standards for content generation in models such as DALL-E and StableDiffusion. Building multimodal models is hard; In this session we share more about multimodal AI, why you should care about it, what are some challenges you might face and how TorchMultimodal, our new PyTorch domain library eases the developer experience of building multimodal models."
Using Causal Inference Model to Set Up Financial Goals of Company,"In this session, we will talk about innovation in traditional financial planning. We developed a machine learning process to produce quarterly and annual goals for the company. The business question is """"if we do X, what would happen in Y"""". In Economics and Machine learning, this type of question is called """"Causal inference"""" to predict an outcome after an action. In Finance, the company has goals for certain top business metrics such as revenue and number of users, and each business team (marketing, sales, etc.) will be responsible to achieve goals.

The causal inference process will automatically look for factors that can lead to moving a business metric. In our example, one of the top primary goals is to increase revenue. Senior executives want to increase revenue by moving the number of monthly active users (MAU), the cost per acquisition, and several other leadership metrics. If we have a goal of increasing revenue by 20%, how many more MAU should we have? This type of causal question is answered by causal models.

Causal models are not just linear regression. They are machine learning-based models to control other variables as fixed numbers to observe the impact between X and Y. During the session, we not only provide the business problem and results, but also want to provide practical advice in our modeling process. Lastly, we will share unique experience of working with cross-functional leadership from product, marketing, finance, and operations."
A Decade of Machine Learning Accelerators:Lessons Learned and Carbon Footprint,"The success of deep neural networks (DNNs) from Machine Learning (ML) has inspired domain specific architectures (DSAs) for them. Google’s first generation DSA offered 50x improvement over conventional architectures for ML inference in 2015. Google next built the first production DSA supercomputer for the much harder problem of training. Subsequent generations greatly improved performance of both phases. We start with ten lessons learned from such efforts.

The rapid growth of DNNs rightfully raised concerns about their carbon footprint. The second part of the talk identifies the “4Ms” (Model, Machine, Mechanization, Map) that, if optimized, can reduce ML training energy by up to 100x and carbon emissions up to 1000x. By improving the 4Ms, ML held steady at <15% of Google’s total energy use despite it consuming ~75% of its floating point operations. With continuing focus on the 4Ms, we can realize the amazing potential of ML to positively impact many fields in a sustainable way."
Applied Natural Language Processing for Cybersecurity: Taming the Bleeding Edge Language Models for Practical Security Use Cases,"Applied Natural Language Processing for cybersecurity: Taming the bleeding edge language models for practical security use cases

We have new and powerful natural language models cropping up almost every month, each with more than a billion parameters, capable of numerous open-ended human-like language tasks – like conjuring up crazy concoctions of realistic images from unrealistic human descriptions. But how can they be useful for practical purposes in the cybersecurity domain? Have we solved all the low hanging fruits related to existing security bottlenecks and automation of all kinds of security events analysis?

Following questions will be proposed to the panel for discussion:

1. Large Language Models – A new Moore’s Law? Can multibillion parameter models be finally used for practical infosec use cases?

2. Have we explored tried and tested NLP techniques being successfully used in other domains – for e.g. Topic Modeling in advertisement and SEO (Search Engine Optimization) industry – are these being successfully adapted for infosec use cases? What are other examples?

3. Infosec benchmark datasets for language modeling – is enough work being done here? How can we move the needle here?

4. Dangers and pitfalls of open-ended language models in infosec"
Continual Learning of Natural Language Processing Tasks,
The Next Thousand Languages,"Low-resource languages present a challenge for data-hungry approaches to machine translation, speech recognition, and other technologies that promise to open the way for universal participation in the global information society. In this talk I will present a new perspective on the language technology for all (LT4All) agenda, beginning with the structure of the world's linguistic diversity and the actual linguistic challenges on the ground. I will draw on experiences working in societies where there is no clear case for the popular practice of replicating human capabilities in translation or speech recognition, but where there are myriad other opportunities for language technologies. I will describe new ways of working with local communities, oral languages, and human-curated linguistic resources. The result is a radically inclusive approach to language technology which embraces and sustains linguistic diversity."
Causal/Prescriptive Analytics in Business Decisions,"In this talk, I will provide a holistic review of the research methods and tools for causal analytics in business decisions. I focus especially on causal inference in data science. I will discuss a decision tree that helps data scientists to identify the best causal research method based on the problem, context, and the nature of the data. I will draw on my proprietary research on prescriptive analytics (https://docs.google.com/document/d/1b8yaDzriVB2JyIBNQMsUn-uz4bXnsdFe6hTLLTOs1q4/edit). In addition, to give some high-level overviews of the business use cases, I will also draw insights from use cases in the investment industry, and my previous academic role as a Business Professor leading multiple National Science Foundation-sponsored commercial research projects on AI, including Explainable AI (XAI) and Causal Analytics with Human Expertise. Some of the tools and previews can be found on https://www.gopeaks.org/applications."
Responsible AI a Global Imperative for Governments and Business – Now and the Future,"AI is ever more ubiquitous in our lives but all countries are not created equal in their access to or use of AI. Likewise all countries and businesses do not adhere to the same regulatory frameworks or opinions on governance. Yet all companies would benefit from knowing where they stand so that investment in technology is not ultimately wasted. Likewise, access to AI is being used as a geopolitical tool. What lessons are we able to draw and adopt now and how might this thinking mature into the future."
Making ML Scaling Easy,"Over the past decade the computation demands of machine learning (ML) workloads have grown much faster than the capabilities of a single processor, including hardware accelerators such as GPUs and TPUs. As a result researchers and practitioners have been left with no choice but to distribute these workloads. Unfortunately, developing distributed applications is very challenging. In this talk I will present two projects we developed at UC Berkeley, Ray (https://github.com/ray-project/ray) and Alpa (https://github.com/alpa-projects/alpa), that dramatically simplify scaling ML workloads"
"Why you can’t Apply Common Software Best Practices Directly to Data Workflows, and What you can do About it","Every day, virtual mountains of data are collected and stored at unfathomable speeds. As data volume grows exponentially, the data workflow becomes more complex as an avalanche of data makes it challenging to identify, cleanse, mine, pivot and use it for both insights and AI powered product features.

To derive the most value from their data, data professionals must be able to set up their workflow in a way that will maximize not only their own efficiency and productivity but also data reproducibility. To do this, data teams borrow a lot of best practices from software engineering like testing, version control, documentation and continuous integration and deployment (CI/CD), but there are important differences in how these are implemented with data workflows that hamper the success of data teams.

This presentation will outline the specific challenges to adopting software engineering best practices for data and analytics workflows, why they exist, and how data scientists can craft environments to best address common pitfalls and encourage reproducibility.

Specifically:

- what it really means to ‘version control’ data sets (and why it's not what most people think). The session will elaborate on the different motivations for version control in production software environments and production data environments, and discuss best practices for versioning in a data specific workflow..
- what CI/CD needs to look like to best enable a team to collaborate on a data workflow. For example, how to best design data integration tests that go beyond checking for null or unexpected values to enable a team to make changes to a data workflow without compromising downstream dependencies.
- “the why” behind several canonical data modeling best practices that are prevalent today (e.g. a staging layer in your data model), and how they contribute to reproducibility in data workflows.

The session will cover specific actions leaders can take and offer real life examples and use cases. Attendees will walk away with a deeper understanding of how to avoid common pitfalls, how to improve team collaboration and reproducibility in data workflows."
Four Reasons the Data Science Development Experience Sucks,
HP’s 3D Digital Twin: Synthesize Data and Domain Science to Improve Additive Manufacturing Production Yield,
Data Analytics at Scale: A Four-legged Stool,"In this talk, I discuss four tactics that enable successful enterprise analytics efforts. The first concerns data integration. Because essentially all enterprise data resides in data silos, an integration effort is required before meaningful cross-silo analysis is possible. Data science practitioners routinely report spending at least 80% of their time doing “data preparation” (aka data munging). I describe why this activity is hard and tactics that can be employed to make it less costly. Once one has clean cross-silo data, then two further tactics entail using an analytics suite and an information discovery tool. The first is required to do data analytics while the second is necessary when one doesn’t know what analysis to perform. I discuss desired features of each tool, as well as make some comments about machine learning. The fourth tactic entails data lakes and lake houses. Please put everything in a DBMS, so the integration challenge of data lakes is as manageable as possible."
Data Science Without Data Collection Using FedScale,"Cloud computing has successfully accommodated the three """"V""""s of Big Data into data science, but collecting everything into the cloud is becoming increasingly infeasible. Today, we face a new set of challenges. A growing awareness of privacy among individual users and governing bodies is forcing platform providers to restrict the variety of data we can collect. Often, we cannot transfer data to the cloud at the velocity of its generation. Many cloud users suffer from sticker shock, buyer's remorse, or both as they try to keep up with the volume of data they must process. Making sense of data closer to its home is more appealing than ever.

Federated learning is a growing field that attempts to address this challenge by distributing learning and analytics tasks to end-user devices. Although theoretical federated learning research is growing exponentially to meet these challenges, we are far from putting those theories into practice. In this talk, I will introduce FedScale, a scalable and extensible open-source federated learning and analytics platform. It provides high-level APIs to implement algorithms, a modular design to customize implementations for diverse hardware and software backends, and the ease of deploying the same code at many scales. FedScale also includes a comprehensive benchmark that allows data scientists to evaluate their ideas in realistic, large-scale settings. I will highlight a select few systems successfully built using FedScale and share insights from benchmarking recent algorithms using FedScale."
Super Data Science Podcast with Jon Krohn: Responsible Decentralized Intelligence featuring Dawn Song,
"Scalable, Real-Time Heart Rate Variability Biofeedback for Precision Health: A Novel Algorithmic Approach","Heart rate variability biofeedback (HRV-B) is a clinically effective therapy in which patients can improve their mental and physical well-being through real-time monitoring of the heart-rate and specialized breathing techniques. HRV-B can improve health outcomes in a number of medical or wellness-related conditions, ranging from depression and anxiety, to cardiovascular disease, asthma, cancer fatigue, women’s health, better sleep, peak athletic performance, and stress resilience. The effectiveness of HRV-B in treating these conditions is due to how it modulates the nervous system connections linking the brain and heart, particularly the baroreflex. HRV-B is now entering digital health and wellness; however, traditional metrics and algorithms were designed for research or in-person clinical care. Hence, Dr. Aschbacher brings her unique integrative experience as a Head of Data Science, an Adjunct Associate Professor at UCSF, and a licensed, HRV-certified Psychotherapist in order to present a novel algorithm that runs real-time in an app, provides user feedback that is actionable and immediate, and personalizes the challenge for each user’s unique physiology. You will learn: 1) who benefits most from HRV-B, 2) how to model it from a data science perspective, and 3) why it represents a unique market differentiator. We present a novel algorithm that combines nonlinear machine learning models with time series analytic and signal processing techniques in order to derive an algorithmic strategy to provide real-time HRV biofeedback. The pipeline employed is built using interbeat interval data collected from several thousand users of a digital mental health program, and involves SQL, python, and javascript code run in a Google Cloud infrastructure. Finally, we employ user-centered design and behavior change principles to build the precision models in a manner intended to achieve clinically meaningful outcomes. This presentation is geared to provide audience members at all levels with an accessible introduction to HRV-B as a treatment tool, with the data algorithmic portions focused toward an intermediate level of proficiency."
From AutoML to AutoMLOps,"Most data science teams start their AI journey from what they perceive to be the logical beginning: building AI models using manually extracted datasets. Operationalizing machine learning, in the sense of considering all the requirements of the business; handling online and federated data sources, scale, performance, security, continuous operations, etc. comes as an afterthought, making it hard and resource-intensive to create real business value with AI.

Today, forward-thinking enterprises are taking a new, production-first approach to MLOps. This means designing a continuous operational pipeline, and then making sure the various components and practices map into it. Automating as many components as possible, constantly measuring business metrics and making the process repeatable, so that it generates measurable ROI for the business.

In this session, we will describe the challenges in operationalizing machine & deep learning. We’ll explain the production-first approach to MLOps pipelines - using a modular strategy, where the different components provide a continuous, automated, and far simpler way to move from research and development to scalable production pipelines. Without the need to refactor code, add glue logic, and spend significant efforts on data and ML engineering.

We will cover various real-world implementations and examples, and discuss the different stages, including automating feature creation using a feature store, building CI/CD automation for models and apps, deploying real-time application pipelines, observing the model and application results, creating a feedback loop and re-training with fresh data."
Addressing the High Failure Rate of AI & ML Projects – Practical Examples from the Field,"Despite the rapid evolution of AI, projects still fail at a disappointingly high rate. In the past, capturing data at scale and building models was the challenge, but today we're confronted with the issue of making AI more robust while avoiding the risk of unintended consequences. While the tools are new, many challenges remain the same. In this talk, I will share real-world stories and applied examples that demonstrate:
* How to build the business case for an AI project (and get buy-in)
* Navigating AI project management to prevent failure
* How to mitigate the risks of unintended consequence from using AI"
Unified and Efficient Multimodal Pretraining Across Vision and Language,"In this talk, I will present work on enhancing the important aspects of unification, generalization, and efficiency in large-scale pretrained models across vision and language modalities, via different methods and directions of visual grounding for improving both multimodal and text-only NLU tasks. We will start by discussing joint vision and language pretraining models such as LXMERT (large-scale cross-modal pretraining). Next, we will present VL-T5 to unify several multimodal tasks (such as visual question answering, referring expression comprehension, visual reasoning/entailment, visual commonsense reasoning, captioning, and multimodal machine translation) by treating all these tasks as text generation. We will then discuss the direction of improving text-only NLU tasks via visually-grounded supervision and distillation from image and video knowledge transfer (Vokenization, VidLanKD). Finally, we will look at parameter/memory efficiency in VL pretraining via adapter/sidetuning, sparse sampling, and audio replacement methods."
A Tale of Adversarial Attacks & Out-of-Distribution Detection Stories in the Activation Space,"Most deep learning (DL) models assume ideal conditions and rely on the assumption that test/production data comes from the in-distribution samples from the training data. However, this assumption is not satisfied in most real-world applications. Test data could differ from the training data either due to adversarial perturbations, new classes, generated content, noise, or other distribution changes. These shifts in the input data can lead to classifying unknown types, classes that do not appear during training, as known with high confidence. On the other hand, adversarial perturbations in the input data can cause a sample to be incorrectly classified. In this talk, we will discuss approaches based on group-based and individual subset scanning methods from the anomalous pattern detection domain and how they can be applied over off-the-shelf DL models."
Responsible AI Is Not an Option,"Artificial intelligence (AI) is today widely used to inform and shape strategies and services across a multitude of industries. But the decisions made by AI algorithms can appear callous and even careless. In his talk “Responsible AI Is Not an Option,” Dr. Scott Zoldi brings to bear his decades of experience in delivering analytic innovation in a highly regulated environment, to underscore the urgency with which the topics of AI fairness and bias must be ushered onto Boards of Directors’ agendas. In his dynamic presentation, Dr. Zoldi spells out the “why” and “how” of fulfilling the social covenant and soon, regulatory requirements of enterprises using AI ethically, transparently, securely and in their customers’ best interests.

Dr. Zoldi will provide prescriptive advice on how to identify key business risks associated with AI and best practices to proactively mitigate them. He approaches the challenge from his dual role as a business leader and a data scientist, presenting the steps to create a culture of AI responsibility and enforce it with Responsible AI governance. These eight fluid steps comprise:

1. Build a diverse team
2. Establish a robust foundation
3. Respect the power of data
4. Ensure explainability
5. Establish Ethical AI guardrails
6. Make AI innovation efficient
7. Establish proper governance
8. Evangelize responsibility

With roots and training as a physicist tempered with operational reality, Dr. Zoldi’s presentation deftly navigates AI’s power to transform the world with the recognition that with great power comes great responsibility. In this way, “Responsible AI Is Not an Option”—it’s a top requirement for all modern businesses."
Tackling Supply Chain Issues with Data and Analytics – Tales from the War Room,
Detecting Changes Over Time with Bayesian Change Point Analysis in R,Did my data change after a certain intervention? This is a common question with data observed over time. Classical statistical and engineering approaches include control charts to see if the series falls outside of the normal boundaries of expected data. A Bayesian approach to this problem calculates the probability that the data series changes at every point along the series. Bayesian change point analysis allows the analyst to evaluate a whole series and look where the highest probability of change occurred. Has the financial asset lost value after the recent financial report? Are the healthcare outcomes at this hospital better after our new process to help patients? Did the manufacturing process improve after upgrading the machinery? All these questions and more can be answered with these techniques which will be shown in R.
Improving Predictions on High-Resolution Aerial Video Using Multi-Stage Convolutional Neural Networks,"Is your Generative adversarial neural network (GANs) not producing representative synthetic data? If yes, that is no surprise because training a GAN to produce quality data representative of the natural distributions is more complex than traditional predictive modeling. Ensuring the data is representative often requires an analysis of the covariate relationships and a comparison of the moments in the synthetic and natural (actual) distributions. This presentation will detail how a genetic algorithm can be combined with a set pseudo discriminators to automate constructing a better GAN."
Interpretable AI or How I Learned to Stop Worrying and Trust AI,"With breakthroughs in areas such as image recognition, natural language understanding and board games, AI and machine learning are revolutionizing various industries such as healthcare, manufacturing and finance. As complex machine learning models are being deployed into production, the understanding of them is becoming very important. The lack of a deep understanding can result in models propagating bias and we’ve seen examples of this in criminal justice, politics, retail, facial recognition and language understanding. Explaining or interpreting AI is a hot topic in research and the industry, as modern machine learning algorithms are black boxes and nobody really understands how they work. Moreover, there is EU regulation now to explain AI under the GDPR “right to explanation”. Interpretable AI is therefore a very important topic for AI practitioners. In this talk, I will give an overview of a few state-of-the-art interpretability techniques and how you could build explainable AI systems."
Open-source Data Curation and Governance for Large and Growing Data Lakes,"Data Lake Technology provides a powerful way to process, refine, and present huge volumes of diverse data. But this comes at a cost. As a Data Lake evolves, it grows in size and complexity. If not properly managed, a Data Lake can outgrow the abilities and resources of the team that manages it, negatively impacting the usefulness of an organization’s data and slowing or halting the team’s implementation of new analytics and applications. In this talk, Roger Dev showcases how the open source HPCC Systems platform has developed an open-source data curation and governance system called Tombolo to complement the powerful storage and compute capabilities of the HPCC Systems Data Lake operating system.

Session Outline:

Roger will demonstrate how the system enables you to:

1. Curate data – the ability to automatically identify and classify a data file
2. Govern sensitive data – automatically identify sensitive data files, apply any necessary usage restrictions to that data, and
3. Keep accurate records - of who, how, and when a user or application interacts with a sensitive data file"
Women’s Ignite,
Causal AI,"Causal inference is increasingly an indispensable tool of data science, machine learning, and data-driven decision-making. In this talk I will present the state-of-play in causal machine learning. I cover the problems that matter in practice, with emphasis on the tech and retail industries. I will also talk about trends in opensource tools for causal inference. Finally, I'll show examples from DoWhy and its sister package EconML, which together form the PyTorch of causal inference."
Rethinking ML Development – A Data-Centric Approach,"Data-centric AI is bridging the gap between research and practice. Instead of optimizing our algorithms and architectures, pivoting to focus on data as the primary way to improve our machine learning models is yielding tremendous results. But this shift to data has left some gaps in our development process, and with this shift, we need to rethink how we develop AI from tooling to processes.

Session Outline:

In this presentation join us as we examine:
● Data Centric AI and how did we get here?
● Data as the new ‘Source Code’
● What are the practical steps towards Data Centric AI"
"Introduction to Generative Art with Stable Diffusion, presented by HP Inc","Hot on the heels of popular text-to-image Generative Art models like OpenAI's DALLE 2 and Midjourney, Stable Diffusion is an open source Latent Diffusion model that can be used to create images from just a few words. This talk will go through high level details of how the model was built and trained, and some of the precursors models that it built upon. Then it will move to some comments on the ethical implications of AI art models generally and ethical considerations for those using stable diffusion and models like it. The main portion of the talk will be covering with how to get started using Stable Diffusion. This will help those even with limited background in ML or deep learning techniques to get an understanding of practically how to work with the model. This section will also focus on tips, tricks and examples to improve your output images as well as hardware considerations when running this powerful model locally. Finally we will finish with a couple of examples of how this model can be used in a few specific workflows or applications and some examples of what future generative art models may be able to do."
"Human-Friendly, Production-Ready Data Science with Metaflow","In this talk, you will learn about: * What to expect from a modern ML infrastructure stack. * Using tools such as Metaflow to boost the productivity of your data science organization, based on lessons learned from Netflix and many other companies. * Deployment strategies for a full stack of ML infrastructure that plays nicely with your existing systems and policies."
Introduction to Differential Privacy Concepts,"Differential Privacy provides a robust concept of privacy through a mathematical framework for quantifying and managing privacy risks. It is studied in the context of the collection, analysis, and release of aggregate statistics ranging from simple statistical estimations to machine learning. It is an emerging topic with growing interest as an approach for satisfying legal requirements for privacy protection of personal information. Differential privacy can be viewed as a technical solution for protecting individual privacy to meet legal or policy requirements for disclosure limitation while analyzing and sharing personal data. Using examples and some mathematical formalism, this talk will introduce differential privacy concepts including the definition of differential privacy, how differentially private analyses are constructed, and how these can be used in practice."
Impact of Data Science on Social Media Data,"This session will cover data generated on social media and how it is consumed. This data is used for data science applications in a variety of different ways. The platforms themselves use it for data intelligence, but also independent brands use social media data for several applications. Furthermore, content creators, researchers, and businesses across many verticals apply Machine Learning and Deep Learning on social media data for a variety of purposes. Data analytics, marketing campaigns, stock price predictions, recommendation systems, mental health indicators, and chatbots are some examples of the data science applications.
Given that social media is such a large part of our everyday lives today and it is highly influenced by data science algorithms, several layers of historical and sectional biases have inevitably made their way into the models and incidentally into our everyday lives. Biases and challenges will be discussed along with efforts underway for a better informed future."
AI TCO (Total Cost of Ownership) Considerations from Pilot to Production Scale,"AI projects can start small, from pretty much anywhere. Data scientists work from their laptop, workstation, cloud resources, or from resources within powerful servers and storage in a data center. Fast and reliable results will vary depending on the data, models and the infrastructure resources powering your data ingestion, analysis, model building, training, and optimization. Learn about the TCO considerations as you scale AI from exploratory pilot phases to production."
DS/AI for Incident Response & Threat Hunting with CHRYSALIS & DAISY,"There is a lot of talk about the use of AI in Cybersecurity these days. Lots of cybersecurity vendors claim that their products use AI for detecting and stopping threats, but very little information is available on how they do it.

Talking specifically about Incident Response and Threat Hunting... What does it take to transform traditional Threat Hunters/Forensicators into AI-Enhanced ones so they can unleash the power of AI in their day to day investigations?

Discover in this talk by Senior DFIR SANS Instructor Jess Garcia how to transparently use AI in Incident Response and Threat Hunting with the help of the DS4N6 toolset (DAISY VM & CHRYSALIS) and learn about the most useful ML algorithms for this purpose."
What Analytics Leaders need to know about EXplainable AI (XAI),"With the increased use of black-box models, analytics management needs to better understand the options available to them and also their teams. The two primary options are building transparent from the start (interpretable machine learning) or adding an explanatory layer to a black- box model (Explainable AI, also called XAI). We will discuss the advantages of each, and some of the reasons that black-box models are prevalent, even in regulated industries. We will also discuss the two primary kinds of model explanations: local and global. Each will be defined, with examples. Several popular and recent techniques will be overviewed, including SHAP, LIME, counterfactuals, and surrogate models. Despite the brevity of the talk, attendees will leave with a solid overview and a basic taxonomy of popular model explainability options."
Neutralizing Subjectivity Bias with HuggingFace Transformers,"The NLP task of text style transfer (TST) aims to automatically control the style attributes of a piece of text while preserving the content, which is an important consideration for making NLP more user-centric. In this session, we will explore text style transfer through an applied use case — neutralizing subjectivity bias in free text. Along the way, we’ll describe our sequence-to-sequence modeling approach leveraging HuggingFace Transformers, and present a set of custom, reference-free evaluation metrics for quantifying model performance. Finally, we’ll conclude with a discussion of ethics centered around our Applied Machine Learning Prototype: Exploring Intelligent Writing Assistance."
Unified Data Science Platform for Accelerating Data Insights,"We at LinkedIn leverage Jupyter notebooks extensively to do ad-hoc data analysis and our data scientists, engineers and developers spend a lot of time iterating over the query development lifecycle. We have created a hosted notebook platform at LinkedIn for our internal users) called Darwin (Data Analytics & Relevance Workbench at LinkedIn) - a one-stop solution for a complete Jupyter notebook/query life cycle (query development, query testing and query productionizing). Requirements for query development include connecting to various data sources like HDFS, MySQL, Kafka, etc., utilizing data engines like Apache Hadoop, Apache Spark & Trino and using libraries like TensorFlow to build state of the art machine learning models. Requirements for query testing include viewing the result in tabular format, pivot over the same and analyze with the help of visualization tools and collaborating with peers using Git and RB. Requirements for query productionizing include creating a shareable report link of the executions, scheduling the query at a set frequency & publishing the query to another internal app. We will also present the capabilities that we have added in our hosted notebook platform to iterate/pivot/visualize using a customized extension developed called a workbook along with features for productionizing them with creating custom schedules, creating customized dashboards & sharing seamlessly with other users.

We will share the advancements done in this field of Jupyter notebooks over the past few years which enables any user to be more productive with ad-hoc analysis using Jupyter notebooks. These learnings will enable data scientists/ machine learners to easily iterate and share their findings with the broader community.

LinkedIn is a data-driven company. Every team consumes and produces data that improves user experience on LinkedIn. Join Swasti Kakker and Manu Ram Pandit to explore the scalable, extensible unified platform LinkedIn is building leveraging Jupyter Hub, Jupyter Notebook, Docker and Kubernetes, MySQL, Git, and Restli that enforces productive data science and improves development experience."
Beyond Observability for the Modern Data Stack,
Graph Data Science: The Secret Ingredient for Relationship-Driven AI,"You’ve probably heard that graph databases are a major trend in data science and analytics, and you may have wondered how to translate the buzz into business value.

In this session, you’ll learn about the fundamentals of graph data science: what graphs are, how they can be incorporated into your analytics practice, and how a connected data platform can help you move from proof of concept to production.

We will highlight real-world use cases from leading enterprise companies including fraud, recommendations, and supply chain optimization. You’ll discover how it’s possible to translate state of the science techniques into practical business value across multiple industries and use cases."
Applications of NLP in Retail/E-commerce,"This talk covers 3 examples of using NLP to solve problems in a retail e-commerce context. The NLP techniques are topic modeling and string similarity. All the code examples use open source python libraries. The business contexts in which they will be discussed are identifying customer complaints from online reviews, identifying sample products and identifying similar products. Customer complaints are identified from a corpus of google reviews. The store operations team conducted this exercise to find out how often customers complain about problems like lack of adequate parking in large stores. New problems in stores were also identified. We walk through an example of topic modeling, as well as data cleaning for string data. Another problem at Home Depot is that many vendors sell products through our website. An interesting effect of this is that some samples are sold by vendors different from the vendor who sells the main item. Some tile samples are not linked to the items so they do not show up on the product webpage. Our user research shows that items with samples have higher online sales. We walk through some measures of string similarity like Levenstein distance and cosine similarity and their advantages and disadvantages. Lastly, a pretty standard recommender system on any e-commerce website nowadays is “Similar Items”. NLP techniques can be used on a corpus of all the product titles and descriptions to identify such products. The dataset here is too large to use the previously discussed methods. In this case we walk through string embeddings and nearest neighbors on the embeddings to identify the most similar items. The first and third examples will be reproduced with small datasets since yelp reviews and product names are publicly available data. The second one I am reasonably certain I can use a toy dataset."
Search and Discovery in News and Research,"How do you build a search and discovery system for financial news and research? In this talk, we will look at Bloomberg's decade-long investment in three specialized areas in the field of AI: natural language processing (or, the application of machine learning methods to text), information retrieval and search, and core machine learning (including deep learning), and how this is enabling us to apply autocompletion, query understanding, index enrichment (topics, people, sentiment), question answering, summarization, and relevance ranking in order to enable our clients to discover insightful information from the complexity of unstructured data."
Real-time Field Extraction on Mobile-devices Using Machine Learning,"Extracting key-fields from a variety of document types remains a challenging machine learning problem. Services such as AWS and Google Cloud provide text extraction products to """"digitize"""" images or pdfs. These return phrases, words and characters with their corresponding coordinate locations. Working with these outputs remains challenging and unscalable as different document types require different heuristics. The speed-limit for extracting information remains in the ~3-5+ seconds range, too slow for utilizing video and AR to present results

We propose a compressed on-device solution that extracts fields in sub-second range, with speeds approaching 200ms on modern devices for field extraction from invoices and receipts. Real-time scanning and extraction opens up new possible product workflows.

Bill.com is working to build a paperless future. We parse through millions of documents a year ranging from invoices, contracts, receipts and a variety of other types. Understanding those documents is critical to building intelligent products for our users."
Building Production-Ready Recommender Systems with Feast,"Recommender systems are highly prevalent in modern applications and services but are notoriously difficult to build and maintain. Organizations face challenges such as complex data dependencies, data leakage, and frequently changing data/models. These challenges are compounded when building, deploying, and maintaining ML pipelines spans data scientists and engineers. Feature stores help address many of the operational challenges associated with recommender systems.

In this talk, we explore:
• Challenges of building recommender systems
• Strategies for reducing latency, while balancing requirements for freshness
• Challenges in mitigating data quality issues
• Technical and organizational challenges feature stores solve
• How to integrate Feast, an open-source feature store, into an existing recommender system to support production systems"
On Learning-Aware Mechanism Design,"Statistical decisions are often given meaning in the context of other decisions, particularly when there are scarce resources to be shared. Managing such sharing is one of the classical goals of microeconomics, and it is given new relevance in the modern setting of large, human-focused datasets, and in data-analytic contexts such as classifiers and recommendation systems. I'll briefly discuss several recent projects that aim to explore the interface between machine learning and microeconomics, including leader/follower dynamics in strategic classification, a Lyapunov theory for matching markets with transfers, and the use of contract theory as a way to design mechanisms that perform statistical inference."
Is My NLP Model Working? The Answer is Harder Than You Think,"As natural language processing now permeates many different applications, its practical use is unquestionable. However, at the same time NLP is still imperfect, and errors cause everything from minor inconveniences to major PR disasters. Better understanding when our NLP models work and when they fail is critical to the efficient and reliable use of NLP in real-world scenarios. So how can we do so? In this talk I will discuss two issues: automatic evaluation of generated text, and automatic fine-grained analysis of NLP system results, which are some first steps towards a science of NLP model evaluation."
Robust and Equitable Uncertainty Estimation,"Machine learning provides us with an amazing set of tools to make predictions, but how much should we trust particular predictions? To answer this, we need a way of estimating the confidence we should have in particular predictions of black-box models. Standard tools for doing this give guarantees that are averages over predictions. For instance, in a medical application, such tools might paper over poor performance on one medically relevant demographic group if it is made up for by higher performance on another group. Standard methods also depend on the data distribution being static — in other words, the future should be like the past.

In this lecture, we will describe a new technique to address both these problems: a way to produce prediction sets for arbitrary black-box prediction methods that have correct empirical coverage even when the data distribution might change in arbitrary, unanticipated ways and such that we have correct coverage even when we zoom in to focus on demographic groups that can be arbitrary and intersecting"
Vector Search – A Gentle Introduction,"Today, we've gotten used to natural language search and recommendation systems. We expect to get what we search for without remembering the exact keyword. To tackle this, we use ML models that create vectors which represent the semantics of data, and a way to efficiently store and retrieve large amounts of vector and non-vector data. Scaling ML models to work reliably in production is hard and implementing efficient vector search while keeping real-time CRUD support that is expected from databases is even harder.

Vector search engines form a solution to these challenges. A vector search engine helps you create machine-learning-first search and recommendation systems based on your data. It searches through your data super-fast with Approximate Nearest Neighbor (ANN) search, while also supporting all CRUD operations and data mutability.

In this session, you will learn what vector search is, why and when you would need it and you will see vector search in action during live demos."
Taming Large Language Models into Trustworthy Conversational Virtual Assistants,"What if computers can truly converse with us in our native tongue? Computers will transform into effective, personalized assistants for everybody. Commercial chatbots today are notoriously brittle as they are hardcoded to handle a few possible choices of user inputs. Recently introduced large language neural models, such as GPT-3, are remarkably fluent, but they are prone to hallucinations, often producing incorrect statements. This talk describes how we can tame these neural models into robust, trustworthy, and cost-effective conversational agents across all industries and languages."
AI-driven Healthcare Navigation,"Our world faces increasingly complex challenges: we destabilized the climate, haven’t beaten all diseases, and haven’t spread the values of democracy and freedom to large parts of the globe, where violence and riots reign supreme. The world must be fixed in our generation - everyone would agree. But in order to take action, build a plan, we need to see the complete picture, and empower decision makers with tools to make those changes. This decade, we have finally reached a critical amount of data to facilitate the creation of such tools.My work is inspired by Mark Twain’s quote, who once said: “The past does not repeat itself, but it rhymes."" Although future events have unique circumstances, they typically follow familiar past patterns. Over the past few years, I devoted my life to development of prediction techniques. My system inferred that Cholera outbreaks in land-locked areas are more likely to occur following storms, especially when preceded by along drought. Another inference is that genocide events tend to occur following events where local opinion makers describe minority groups as pests. These types of patterns are composed of several abstractions, over variable-term temporal extents and selected from a large number of possible causes.  The algorithms I developed deal with the complexity of discovering such patterns.Large-scale digital histories, social and real-time media, and human web behavior are harvested and augmented with human knowledge mined from the web to afford real-time estimations of likelihoods of future events. Most recently, these algorithms have accurately predicted the first Cholera outbreak reported in Cuba in fifty years. These types of actionable predictions, that enable preventative measures, have drawn the attention of a UN genocide-prevention organization and the Gates foundations and illustrate the vast potential for real impact on the state of humanity.In the last few years I have been focusing on applying similar techniques for the healthcare and Pharma, leveraging large amount of data obtained from both medical records, EMR and other medical research results data in a quest to create an AI system for automated medical research and breakthroughs."
Human Factors of Explainable AI,"There are many types of users and stakeholders that require Explainable AI. Without explanations, end-users are less likely to trust and adopt ML-based technologies. Without a means of understanding model decision making, business stakeholders have a difficult time assessing the value and risks associated with launching a new ML-based product. And without insights into why an ML application is behaving in a certain way, application developers have a harder time troubleshooting issues, and ML scientists have a more difficult time assessing their models for fairness and bias. To further complicate an already challenging problem, the audiences for ML model explanations come from varied backgrounds, have different levels of experience with statistics and mathematical reasoning, and are subject to cognitive biases. They will also be relying on ML and Explainable AI in a variety of contexts for a variety of different tasks. Providing human understandable explanations for predictions made by complex ML models is undoubtedly a wicked problem. In this talk I’ll cover the human-factors that influence how explanations are interpreted and used by end-users. I’ll also present a framework for what to keep in mind when designing and assessing interpretable ML systems."
"Building Modern Search Pipelines with Haystack, Large Language Models and Hybrid Retrieval","In this talk, we navigate through the latest buzz around semantic search and separate the noise from the meaningful advancements. Is dense retrieval better than BM25’s keyword search? Do large language models outperform smaller transformers? How well do the models generalize to industry corpora? How can we leverage Question Answering?

We investigate those questions by walking through three main sections in the talk:

1) Short introduction into modern search systems, the main trends in 2022, an overview of typical pipelines behind it and typical challenges in the dev cycle
2) Investigating dense retrieval: With all the hype around vector databases and using transformers like BERT for search, it’s often difficult to understand the maturity of dense approaches for real use cases in the industry. We benchmark the performance of different retrieval methods (dense, sparse, hybrid) to understand where they fail, where they shine and which one might be relevant for your own industry use case. On top, we show how you can easily evaluate all popular methods on your own dataset using the open-source framework haystack.
3) Investigating Large Language models for retrieval: They are all around on social media, but are they actually useful for search? Again, we share benchmarks, observations from our own use cases and demonstrate with open-source code how you can evaluate and compare the performance on your own dataset using haystack.

The session is primarily addressing practitioners who want to get an overview of the state-of-the-art retrieval methods out there and open-source code to evaluate them."
How Enterprises Succeed with MLOps at Scale,"Machine learning and AI are a piece of a larger system. In order to run MLOps at scale, you need people and technology to work together to create repeatable, scalable and reproducible processes. We will discuss how to achieve scale, avoid common problems and look at use cases from major industry players."
Confidential Data Analytics and Learning for Data Scientists,"Data scientists and analysts often wish to analyze confidential data, but these datasets are often locked down due to privacy concerns. Further, it is sometimes difficult to share confidential data between teams in the same organization or across organizations. In this talk, I will overview state-of-the-art techniques for protecting confidential data while _in use_. These methods encrypt the data while enabling data scientists to train models and run analytics queries on encrypted data, essentially """"sharing without showing"""". I will then discuss our research and open source project called Opaque, which enables confidential analytics, learning and collaboration in an easy to use way. Link to open source project: https://github.com/mc2-project/mc2"
"Cloud Directions, MLOps and Production Data Science","Cloud computing promises to simplify infrastructure, but somehow MLOps remains deeply technical, even in the cloud. The complexity of MLOps tends to lead to an organizational antipattern: data scientists who know the data and models best have to mind-meld with data engineers who know the infrastructure best. This is particularly problematic in the highest-value stage of the ML lifecycle — managing models in production.

Recent trends in cloud technology, including serverless computing, promise new approaches for abstracting away infrastructure. Unfortunately these offerings fall short of the challenge of MLOps. In this talk I will cover some of the important promises and weaknesses of current cloud offerings, and describe research from Berkeley's RISElab and the resulting open source Aqueduct system, which are putting Production Data Science at the fingertips of anyone working with data and models."
Machine Learning Models for Quantitative Finance and Trading,"Machine Learning (ML) and Predictive Analytics are now embedded in a broad variety of use cases in Quantitative Finance, from information extraction to sentiment analysis, from factor scoring models to complex instrument pricing methods, and from risk premium mining to portfolio construction models. ML is also being used for asset pricing, e.g, option pricing or illiquid bond pricing where we need to learn the pricing function using data driven techniques as a further enhancement of methods rooted in stochastic modeling.

Quant traders and data scientists require automated ML & AI technologies to quickly extract actionable information from unstructured and increasingly non-traditional sources of data. We will illustrate the use of such derived signals in constructing promising trading strategies through novel use cases.

Session Outline:

This talk will provide a brief overview of the following topics:
• The broad application of machine learning in finance: opportunities and challenges.
• Use of alternative data such as News and Geo-locational/Extreme weather data to build signals and trading strategies for the financial markets.
• Machine Learning techniques for asset pricing, enhancing complex quant models (i.e., PDE solutions, Monte Carlo Simulations) for an efficient pricing of derivative and illiquid securities using data driven methods."
Build an ML Testing Infrastructure for Rigorous and Systematic Model Testing,
Automatic DataFrame Profiling and Visualization for Machine Learning,"When faced with a new dataset for a Machine Learning task, there are common questions that every data scientist will ask themselves about the data, and common preprocessing and cleaning operations to be performed. This can be laborious and time consuming using pandas alone, and looking at all columns and their interactions can become infeasible for larger datasets. In this talk, we'll see how the dataset on-boarding process for machine learning can be greatly simplified by using the dabl library in Python, which provides interactive suggestions for data cleaning and visualization. Using selection techniques specifically tailored to supervised learning, dabl will detect data types, apply required cleaning and preprocessing and select relevant visualizations automatically. This allows speeding up the on-boarding of new datasets tremendously and provides immediate feedback and insights."
Building Reliable Lakehouses for your ML pipelines with Delta Lake,
Creating Adhoc Data Science Teams for Local Politics,"It's election season, and you're on the campaign trail. You've set up your website, you've been knocking on doors, making phone calls, getting endorsements, and attending rallies, but there's only so much you can do to get your message out there. You need data to make informed decisions about where to focus your efforts, but you don't have the time or resources to hire full-time data scientists. What do you do?

In this talk, I'll discuss how to create adhoc data science teams to help with local elections. We'll cover how to structure projects to collect data, continually inform your campaign strategy, and communicate with a variety of backgrounds.

This talk will discuss how to create ad hoc data science teams to support local political initiatives. It will cover using notebooks to collect and analyze data, as well as how to effectively communicate findings to:

* candidates (or measure/bond leads)
* campaign staff
* the media

By the end of this talk, you'll have the tools you need to enable people to make data-driven decisions on the campaign trail and communicate."
"Orchestrating Data Assets instead of Tasks, with Dagster","Data practitioners use orchestrators to schedule and run the computations that keep data assets, like datasets and ML models, up-to-date.

Traditional orchestrators think in terms of “tasks”. This talk discusses an alternative, declarative approach to data orchestration that puts data assets at the center. This approach, called “software-defined assets”, is implemented in Dagster, an open source data orchestrator.

In traditional data platforms, code and data are only loosely coupled. As a consequence, deploying changes to data feels dangerous, backfills are error-prone and irreversible, and it’s difficult to trust data, because you don’t know where it comes from or how it’s intended to be maintained. Each time you run a job that mutates a data asset, you add a new variable to account for when debugging problems.

Dagster proposes an alternative approach to data management that tightly couples data assets to code - each table or ML model corresponds to the function that’s responsible for generating it. This results in a “Data as Code” approach that mimics the “Infrastructure as Code” approach that’s central to modern DevOps. Your git repo becomes your source of truth on your data, so pushing data changes feels as safe as pushing code changes. Backfills become easy to reason about. You trust your data assets because you know how they’re computed and can reproduce them at any time. The role of the orchestrator is to ensure that physical assets in the data warehouse match the logical assets that are defined in code, so each job run is a step towards order.

Asset-based orchestration works well with modern data stack tools like dbt, Meltano, Airbyte, and Fivetran, because those tools already think in terms of assets.

Attendees of this session will learn how to build and maintain data pipelines in a way that makes their datasets and ML models dramatically easier to trust and evolve."
CI/CD for Machine Learning,"CML is a project to help ML and data science practitioners automate their ML model training and model evaluation using best practices and tools from software engineering, such as GitLab CI/CD (as well as GitHub Actions and BitBucket Pipelines). The idea is to automatically train your model and test it in a production-like environment every time your data or code changes.

Session Outline:

In this talk, you’ll learn how to:
- Automatically allocate cloud instances (AWS, Azure, GCP) to train ML models. And automatically shut the instance down when training is over
- Automatically generate reports with graphs and tables in pull/merge requests to summarize your model’s performance, using any visualization library
- Transfer data between cloud storage and computing instances with DVC
- Customize your automation workflow with GitLab CI/CD"
Ace the Data Job Hunt,"Want to land your dream job in data? Learn what makes a Data resume stand out, how a portfolio project is a job hunting cheat code when you avoid these 6 mistakes, why cold email is a networking super-power, and how to craft a winning personal story for the behavioral interview. These tips led Nick Singh, best-selling author of Ace the Data Science interview, to work at Facebook & Google, and helped 200+ of his coaching clients land top jobs in tech."
Cybersecurity and Policing in the Metaverse,"Cybersecurity and policing in the metaverse.
You can buy virtual assets in the Metaverse; real estate, investment commodities, stock. This of course means that the Metaverse will need to have security and policing.

AI Play In Electric Vehicles
About Me
My R&D Lab near Silicon Valley
Al in Electric Vehicles.
Increasing Complexity of Mobility Devices.
Areas of AI Potentials in EVs.
Tesla Self Driving Sensor.
Tesla Self Driving.
EV Fuzzy Controller.
What is Fuzzy Logic?
Current R&D Project
Short Video of Car Project"
Tackling Climate Change with Machine Learning,"Climate change is one of the greatest challenges that society faces today, requiring rapid action from all corners. In this talk, I will describe how machine learning can be a potentially powerful tool for addressing climate change, when applied in coordination with policy, engineering, and other areas of action. From energy to agriculture to disaster response, I will describe high impact problems where machine learning can help through avenues such as distilling decision-relevant information, optimizing complex systems, and accelerating scientific experimentation. I will then dive into some of my own work in this area, which merges data-driven approaches with physical knowledge to facilitate the transition to low-carbon electric power grids."
Navigating the Pitfalls of Applying Machine Learning in Practice,"As the amount and complexity of data rapidly increases, machine learning tools are being used for a wide array of analytical tasks. These tasks include supervised and unsupervised prediction and forecasting as well as sophisticated normalization and integration of heterogeneous data sets. Although machine learning has shown great promise in almost every area it has been applied to, mistaken assumptions about the data being used to train such models can lead to erroneous evaluations and to models that do not actually work as well (or at all) in practice. In this session, we will talk concretely about five interrelated pitfalls that one might encounter when using supervised machine learning and how to avoid them. Importantly, these pitfalls are not domain specific --- they can, and do, occur in every industry, and failing to appreciate their significance can cause projects to fail that would otherwise succeed.

Session Outline:

This session will cover five statistical pitfalls:

1. Distributional differences
2. Dependency structure
3. Confounding variables
4. Information leakage
5. Unbalanced data

Each pitfall will have an example, although the first and fourth pitfalls will be discussed the most in-depth. By the end, the audience should have a conceptual understanding of what each of these pitfalls are and how to avoid them.

Background Knowledge:

The audience should understand how machine learning models are trained, i.e. using a training set for training and a separate test set for evaluation, but do not need to know the mathematics behind how any models work. One may get more out of the talk if they have trained a model themself, but that is not a requirement."
5 Things We Have Learned From Continuous Explore Exploit Applications at Netflix,"Netflix is the pioneer for applying causal inference to real life applications. From the down-to-the-root online experimentation platform to a more advanced continuous explore exploit system, all the applications are heavily researched and developed to provide Netflix members the most member joy. Here we aim to provide the five lessons learned by applying Continuous Explore Exploit framework in multiple Netflix applications and hope to shed light on future innovations and applications.

Lesson 1: Setting up the CEE framework can bring huge customer satisfaction gains. In Video artwork, by employing the CEE framework has achieved one of the biggest wins in the area by a simple switch of personalized exploitation with collected explore data. Even just exploiting the only winner can achieve a sizable win.

Lesson 2: Adding in more arms and counterfactual analysis becomes a breeze in mature CEE applications. At Netflix, new features are developed to meet a certain cohort’s needs. With the CEE, we can easily add new arms to the selection portfolio. In this way, we can measure and maintain arm effectiveness continuously without further deployment and AB tests. The results from counterfactual analysis can help with generating hypotheses to improve personalization algorithms.

Lesson 3: CEE could be a faster way to go than AB tests in product launches once the system is in place. The long cycle times and dependence on allocations also constrain the overall number of concurrent tests and for AB tests. CEE would help relieve this pain by continuously launching new features and learning from its efficiency while productizing the most valuable options in exploitation.

Lesson 4: Apple to Apple Comparison is the key to accurate measurement. Whenever conducting counterfactual analysis, one key point is to make sure the population that we compare against are from the same distribution.

Lesson 5: Making sure no customer harm is the initial step to set up CEE for success. Although with all the benefits we can obtain from CEE, there can be potential customer dissatisfaction from the random exploration. We run a no-harm test at Netflix for all applications with CEE to ensure customer satisfaction.

We have summarized many learnings in applying Continuous Explore Exploit framework in various areas across Netflix. We will describe how Continuous Explore data has helped us be faster and smarter with innovation efforts in these areas at Netflix. These insights can bring more ideas into other applicable areas while spark further innovations for industries."
Riding the Tailwind of NLP Explosion,"Keywords: # transformers # transfer leaning # zero-shot # literature review # application

We ingest 2 million documents monthly at CB Insights (CBI) to empower tech decision-makers and researchers. From raw data to insights, the R&D team takes on many holy grail challenges, a major one being how to extract relevant information with scale, speed, and precision.

When we started at CBI, NLP was still prehistoric when the """"bag of words"""" walked the earth. Fast forward ten years, the birth of the """"attention mechanism"""" created an NLP explosion and a strong tailwind for teams big and small to ride.

In this talk, we'll share how we modernized our NLP stack @ CBI R&D and the challenges we met with. Part I will walk you through the timeline and milestones of NLP evolution, highlighting significant trends after the """"attention"""" revolution. Part II will discuss battle-ready lessons gained using transformer models across various tasks and languages, leveraging open source libraries such as HuggingFace Transformers and Pytorch Lightning."
Archetypal Analysis: Maintaining Contrastive Categories in Cluster Analysis,"Cluster analysis is the task of finding and organizing data observations into groups that share characteristics. K-means is a common machine learning technique and is great at finding clouds of concise clouds of homogenous data. K-means works by finding “centroids”, or centers of average tendency in the data, and we simply classify individual observations based on which centroid is mathematically closest to it. Philosophically, we say that the centroids have the characteristics that define what it means to be a member of the given cluster.

In the real world, there are many categories that we do not define by their “average tendency”. For instance, in American politics, we define voter’s political ideology in contrastive categories of liberal and conservative. Even someone who is a moderate liberal we will still categorize as liberal, even if their ideology has more common with a moderate conservative than an extreme liberal. We do this because they have qualities that at least begin to approach a stereotypical extreme. This works for many other categories as well (value shoppers, athletes, action films, etc). K-means will often struggle to organize data this way, as it uses centroids rather than contrastive extremes to exemplify cluster membership.

Archetypal analysis, on the other hand, mirrors that contrastive way of thinking into it’s machine learning approach to clustering data. Like K-means, it finds artificial data points to exemplify cluster membership. But instead of centroids, Archetypal analysis looks for extremal values on the periphery of the data distribution, called “archetypes” to exemplify cluster membership, and cluster membership is defined by their similarities to archetypes. As such, archetypal analysis is a useful tool for maintaining contrastive categories in organizing data into classes.

My presentation will cover archetypal analysis in greater detail, comparing it to more traditional clustering techniques. I will also cover the underlying math and machine learning approach to the technique, as well as its implementation in R. I’ll also share a few case studies from my own industry (Market research) where the technique is used. Attendees should be at least somewhat familiar with cluster analysis generally, be able to follow along in R code, and have a rudimentary understanding of basic statistical and machine learning ideas."
Open Source ELT For Everyone – Level Up With Custom Connectors,"Airbyte has hundreds of source connectors ready-made and available, but there are an ever growing number of data sources you might encounter.It's a familiar feeling for most data engineers to find that your ETL/ELT tool doesn't support some critical connections that you really need. So you introduce another tool, or perhaps you submit a ticket and wait for it to get built. Airbyte's Connector Development Kit gives you the agency to rapidly build those vital connections with ease! This talk will demonstrate setting up a standard connection in Airbyte with pre-built connectors, then walk through the process of building a bespoke API connector with our low-code development kit and using it to sync data."
Real-time Data Science Made Easy,"By 2025, analysts estimate that 30% of generated data will be real-time data.  This is 52ZB of real-time data per year and is roughly the amount of total data produced in 2020!  Soon, almost every data scientist and data engineer will be working with real-time data.  The future of data science is real-time. Existing technologies for working with static data fail when applied to real-time data because they have no way to incrementally update calculations and visualizations.  To make such enormous volumes of changing data useful, we need a toolkit for managing data, performing data science, and visualizing results in real-time.  In this talk, we will explore production-quality, real-time data science using the current leading open, real-time technologies:  Kafka, redpanda, ksqlDB, Materialize, and Deephaven Community Core.

Session Outline:
Concepts that will be discussed:
 Key components needed in a real-time data analytics system and how to choose the best open
options for your use case.
 Why are current static technologies, such as SQL and Pandas, unsuited to real-time data science?
(Transactional DB vs streaming table)
 Design patterns for building flexible real-time workflows.
 Efficiently publishing real-time data to many users in a programming language agnostic way.
 Using both real-time and static data in the same query. 
 Data exploration, visualization, and dashboards in real-time.
 Query language selection for data science: SQL (ksqlDB and Materialize) vs data-frame
(Deephaven).
 Working with time series.
 Real-time AI/ML on streams of data.
 Do current tools, such as Pandas, Matplotlib, and TensorFlow, have a place in a real-time world?"
Resilient Machine Learning,"Every software system experiences incidents. Service outages, data pipeline delays, sudden load, and hundreds of other risks threaten system uptime and damage the user experience. Mature development teams plan for these incidents and build software that adapts to unexpected changes in system behavior and availability. Teams working on safety critical applications sometimes spend more time mitigating these risks than working on everything else put together.

Unfortunately, this kind of risk mitigation is notoriously difficult in a machine learning system. A small change to model inputs can cause large and unexpected changes to model outputs. As a result, software incidents that touch ML systems tend to have a larger blast radius and longer recovery times. This critical vulnerability has slowed the adoption of machine learning technologies in safety critical applications.

In order for machine learning to continue to drive impact in new applications we will need to address this problem directly. We start with testing. ML is software, and good tests are an irreplaceable tool for building a resilient system. We will explore how to design end-to-end simulations to assess our models' resilience.

Next, certain feature encoding strategies are more resilient to sudden distribution shifts than others. For example, models trained with clever default values or hashed bucketized features can be particularly resilient to localized feature outages. We will discuss the dynamics that drive this phenomenon.

Finally, an ML model is a reflection of the task we train it to solve. By cleverly introducing noise to the training process we can build models that perform well even during software incidents. We will dig into the best strategies to engineer tasks for robust and resilient models."
How Far Left Can You Shift? The Tension Between Data Science and ML Engineering,"In this talk we discuss the fundamental differences between how data scientists and machine learning engineers approach the world, and how the resulting tension between them leads to one of the main barriers that must be overcome for ML projects to succeed. We describe how a machine learning platform like Kubeflow can dramatically change how these groups work and collaborate. We present several example scenarios in the lifecycle of a machine learning project, and show how an ML platform increases collaboration, reduces friction, and improves the lives of data scientists and ML engineers. Platforms, and the change in methodology that they enable, can dramatically transform culture, reduce risk, and help improve ML project outcomes."
Optimizing Recommendations for Competing Business Objectives,"Recommender systems are now ubiquitous in e-commerce. At Wayfair, we use a collection of machine learning models to predict which content and which products to show our customers at every stage in their shopping journey. Machine learning models for recommendations are typically trained to optimize for near-term measures of customer satisfaction, such as clicks and conversion. However, there are often other business objectives that can appear to be in conflict with this idealized ranking. For example, some products might have higher margins or lower shipping costs than others, and surfacing such products higher than they would normally be ranked could potentially boost long-term profit. However, such profit boosts will likely come with a decrease in short term clicks and conversion. Thus we need to find ways to balance these competing objectives if we want to make our product recommendations """"profit aware.""""

In this talk I will give an overview of this problem, what makes it difficult, how we have been addressing it at Wayfair, and the lessons that we have learned so far. I will start by giving an overview of the different types of competing business objectives that can arise in the e-commerce use case and how they compete against each other in practice. Along the way I will introduce some of the fundamental concepts of multi-objective optimization, including Pareto Efficiency and the Pareto Frontier, and how they relate to this problem. Finally, I will discuss the pros and cons of various strategies for making recommendation systems profit aware."
Continual Learning: Build Sustainable AI Models in Production,"Nowadays, most machine learning models in production are trained offline with static data inputs. However, data patterns change over time, which can lead to the distribution shift between train data where models are trained and real-world data where models are applied. The discrepancy arises over time, resulting in degrading predictive power in production models. A drift detection and handling mechanism would be required to maintain and further improve model performance for the continual success of AI models in production.

In the talk, we will be presenting the continual learning strategy we are using to address the drift problem and build a sustainable AI system in production. It focuses on consistently responding to changes in data patterns and proactively reacts to performance decays in production, while collects data intelligently over time and evaluates newly trained models on that data for improved performance. The goal is to keep the model performance consistently competitive via long-term model iterations.

Additionally, we will be covering the facilitated infrastructure and resources required to implement the continual learning, to build a sustainable system that is as automated and adaptive as possible, where human involvement is minimized and resources re-utilization is maximized. It includes a codified AutoML framework, MLOps tools, streamlined model deployment and integration pipeline, holistic model monitoring system, task trigger and scheduler system, to be able to continually handles incoming data, performs model development and deploys the new models in a reliable, sustainable, cost effective and time-saving manner that take us a long way down the road of AI adoption in business."
Achieving Techquity: Digital Health Equity,"Healthcare is facing a new frontier. In just a few years, the industry has seen a boom in digital health tools and technologies on both the patient and provider side, along with an explosion of health data, which has been driving increasingly sophisticated predictive and prescriptive insights into individuals and populations.

Unfortunately, this frontier has proven to be hostile to marginalized communities. There is a growing digital divide, where healthcare technology has actually posed challenges, instead of benefits. The barriers to accessing newly digitized care are legion: it’s everything from language barriers to low income, lack of broadband or mobile access, disabilities and physical differences, low digital literacy, a fully understandable mistrust of the healthcare system and much more. The danger is that this divide will continue to grow, and even become insuperable.

Advancing healthcare technology and driving innovation has to be done in a way that is thoughtful about implications and consumption across communities. The challenge is to reach all consumers without exacerbating the disparities that exist in communities today.
Consumers need to be able to access, understand and trust digital channels to use them to improve their health. “Techquity” can be understood as the strategic design, development, and deployment of technology to advance health equity in underserved, vulnerable and at-risk populations, and close the access gap.

Techquity is not an “individual” or consumer-level problem. Rather, promoting or advancing techquity will require collaboration, transparency, inclusivity, and a commitment to ensure organizational transformation at a systemic level, from all stakeholders -- healthcare providers, health tech companies, payers, community leaders, community organizations, policy makers, and patient organizations alike.

This talk will look at the four factors of techquity: digital access, digital literacy, health literacy, and personal preference. The speakers, Tushar Mehrotra, SVP Analytics, Optum and Michael Thompson, VP/Chief of Staff Systems Improvement, Bassett Healthcare Network, will highlight ways leaders can make sure consumers stay on the digital landscape.

Learning Objectives:
• How to build a data-driven map that identifies the health literacy, digital access and social determinants that impact digital engagement and outcomes
• Ideas for addressing the root causes that create barriers to health— and where simple digital solutions can close gaps
• How to offer simple choices to ensure a consumer’s digital experience is consistent across the health journey"
Kedro: The Open Source Python Library for Production-Ready Data Science Code,"This talk will tell a story of how changing business objectives are driving interest in production-level code; what software principles data engineers and data scientists should consider applying to their code to make it easier to deploy into the production environment; and, how they can use an open source Python library, called Kedro, to simplify their workflow.

We will deep dive into Kedro internals, focusing on how configuration, nodes, and modular pipelines can simplify and scale your data science workflow. We will discuss how the framework can plug into existing toolkits, such as MLFlow, DataBricks, and DBT. In terms of new functionality, we will showcase Kedro's experiment tracking component. Finally, we will present an impactful real-world case study and explain how joining the Linux Foundation will benefit the wider community!

We hope the audience of data engineers and data scientists will not only walk out of the session understanding the importance of developing maintainable and modular Data Science code, but also have the fundamental understanding to start working with Kedro immediately."
MLOps for Deep Learning,"In model serving, two important decisions are when to retrain the model and how to efficiently retrain it. Having one fixed model during the entire often life-long inference process is usually detrimental to model performance, as data distribution evolves over time, resulting in a lack of reliability of the model trained on historical data. It is important to detect drift and retrain the model in time. We present an ensemble drift detection technique utilizing three different signals to capture data and concept drifts. In a practical scenario, ground truth labels of samples are received after a lag in time, which we consider appropriate. Our framework automatically decides what data to use to retrain based on the signals. It also triggers a warning indicating a likelihood of drift.

Model training in serving is not a one-time task but an incremental learning process. We address two challenges of life-long retraining: catastrophic forgetting and efficient retraining. To solve these two issues, we design a retraining model that can select important samples and important weights utilizing multi-armed bandits. To further address forgetting, we propose a new regularization term focusing on synapse and neuron importance.

Only a significant minority of companies unlock the true potential of AI as trained models accumulate dust due to challenges in MLOps. Serving reliable AI predictions to customers involves cost, effort, and planning to set up a continuous deployment pipeline. MLOps for Deep Learning demands a carefully crafted deployment pipeline. We discuss our open-source project which is a robust continuous deployment pipeline by integrating our unique drift detection and model retrain algorithms for serving DL models. We show how to efficiently deploy, monitor, and maintain DL models in production using our solution which is a Kubernetes native POC solution."
"Identity, Fidelity and a Very Long Tail of Edge Cases","Decent general use models have used generally obtainable data to prove the utility of many compelling use cases for AI, such as speech recognition, relevance and image recognition. Now that the utility of these capabilities has been proven and the demand to solve more specific business problems unlocks additional investment dollars for AI, I will make the case that these use cases will increasingly focus on refining models with less accessible and more specific data. From rare events to less well-represented demographics, the number of edge cases will increase. Meanwhile increasing regulation, increased privacy protection expectations, tighter infosec requirements and ultimately model explain-ability will challenge us to systematically tighten governance and data management, as well as up the ante for higher fidelity in synthetic data."
The Statistical Engine Behind A/B testing,"Online controlled experiments (A/B tests) have become the gold standard for learning the impact of new product features in technology companies. A/B testing empowers Wish to continuously improve the customer experience and measure the impact of new ideas, market strategies, product features, and machine learning models. At any given time, there are hundreds of experiments running at Wish.

Although the concept of A/B testing is simple, it is challenging to conduct A/B tests at scale. Over the past few years, data scientists and engineers at Wish have substantially evolved the statistical engine ( hereafter engine) of our experimentation platform. The engine provides t-test, ratio metric testing, or percentile metric testing to run hypothesis testing for different types of metrics. When rolling out a neutral feature, the engine runs non-inferiority tests. The engine conducts multiple hypothesis corrections and sequential testings when testing multiple metrics and making decisions sequentially. It also analyzes sample ratio mismatch that verifies that each experiment is unbiased. Further, to ensure the engine's reliability, we run hundreds of simulated A/A and A/B tests to evaluate the false-positive rate and power and various A/A tests to evaluate the false positives holistically.

An open-source python library wishab from Wish implements this statistical engine. We tested the library in the field with the experiments at Wish. Further, The library wishab is platform agnostic. Data scientists at any company can utilize their existing data pipeline to compute the summary statistics, which are inputs for wishab. Lastly, we implemented wishab with scalability in mind and applied it for experiments with hundreds of millions of users."
